{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Deep Learning to Predict Traffic Flow\n",
    "\n",
    "Here, we use multivariate time series to predict the how traffic will be.\n",
    "\n",
    "Could be part of the talk in Budapest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T19:33:18.707960Z",
     "start_time": "2019-05-13T19:33:15.550772Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\";\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\";  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T19:33:19.088903Z",
     "start_time": "2019-05-13T19:33:18.709896Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 14288926065768353170, name: \"/device:XLA_GPU:0\"\n",
       " device_type: \"XLA_GPU\"\n",
       " memory_limit: 17179869184\n",
       " locality {\n",
       " }\n",
       " incarnation: 7441235527448443654\n",
       " physical_device_desc: \"device: XLA_GPU device\", name: \"/device:XLA_CPU:0\"\n",
       " device_type: \"XLA_CPU\"\n",
       " memory_limit: 17179869184\n",
       " locality {\n",
       " }\n",
       " incarnation: 15366897165287552057\n",
       " physical_device_desc: \"device: XLA_CPU device\", name: \"/device:GPU:0\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 22508008244\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 5684342040079447989\n",
       " physical_device_desc: \"device: 0, name: Tesla P40, pci bus id: 099f:00:00.0, compute capability: 6.1\"]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.keras import optimizers\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense, Dropout, LSTM, CuDNNLSTM, Activation\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T19:33:19.784172Z",
     "start_time": "2019-05-13T19:33:19.090818Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import sys\n",
    "from configparser import ConfigParser\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "\n",
    "sys.path.append('/home/mapdadmin/abraham/caltrans-data-exploration/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T19:33:20.145840Z",
     "start_time": "2019-05-13T19:33:19.786139Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exiting Main Thread\n",
      "total time:  9.107589721679688e-05\n"
     ]
    }
   ],
   "source": [
    "from process_traffic_data import apply_custom_transformations\n",
    "import data_processing.process_utils as utils\n",
    "from training import train_utils\n",
    "from omnisci_connector.omni_connect import OmnisciConnect\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T19:33:20.150528Z",
     "start_time": "2019-05-13T19:33:20.147893Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T19:33:20.424984Z",
     "start_time": "2019-05-13T19:33:20.152135Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read configuration file /home/mapdadmin/abraham/ini_files/config.ini\n",
      "Configuration file read.\n",
      "connect to omnisci\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Connection(mapd://abraham:***@http://localhost:6273/abraham?protocol=http)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_path = '/home/mapdadmin/abraham/ini_files/config.ini'\n",
    "print(\"read configuration file %s\" %config_path)\n",
    "config = ConfigParser()\n",
    "config.read(config_path)\n",
    "print(\"Configuration file read.\")\n",
    "\n",
    "print(\"connect to omnisci\")\n",
    "OmnisciHandle = OmnisciConnect(config_path)\n",
    "OmnisciHandle.start_connection()\n",
    "OmnisciHandle.con"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T19:33:20.430209Z",
     "start_time": "2019-05-13T19:33:20.426568Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "select timestamp_, station, freeway, occupancy, speed  from caltrans_historic_2015_2019 WHERE timestamp_ >= '2019-01-01 00:00' AND timestamp_ <  '2019-02-01 00:00' AND freeway = 101\n"
     ]
    }
   ],
   "source": [
    "table_name = \"caltrans_historic_2015_2019\"\n",
    "\n",
    "cols = \"timestamp_, \\\n",
    "station, \\\n",
    "freeway, \\\n",
    "occupancy, \\\n",
    "speed \"\n",
    "\n",
    "condition = \"WHERE timestamp_ >= '2019-01-01 00:00' \\\n",
    "AND timestamp_ <  '2019-02-01 00:00'\"\n",
    "\n",
    "# condition = \"WHERE timestamp_ >= '2019-01-01 00:00'\"\n",
    "\n",
    "\n",
    "query = \"select \" + cols + \" from \" + table_name + \" \" + condition\n",
    "\n",
    "print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T19:33:25.001865Z",
     "start_time": "2019-05-13T19:33:20.432390Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe shape:  (6107278, 5)\n",
      "summary of nan's\n",
      "timestamp_    0\n",
      "station       0\n",
      "freeway       0\n",
      "occupancy     0\n",
      "speed         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df_Omnisci = OmnisciHandle.con.select_ipc(query)\n",
    "print(\"Dataframe shape: \",df_Omnisci.shape)\n",
    "print(\"summary of nan's\")\n",
    "print(df_Omnisci.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T19:33:25.022362Z",
     "start_time": "2019-05-13T19:33:25.005787Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp_</th>\n",
       "      <th>station</th>\n",
       "      <th>freeway</th>\n",
       "      <th>occupancy</th>\n",
       "      <th>speed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-24</td>\n",
       "      <td>6784</td>\n",
       "      <td>101</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>69.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-24</td>\n",
       "      <td>6785</td>\n",
       "      <td>101</td>\n",
       "      <td>0.0077</td>\n",
       "      <td>71.400002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-24</td>\n",
       "      <td>6786</td>\n",
       "      <td>101</td>\n",
       "      <td>0.0242</td>\n",
       "      <td>71.800003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-24</td>\n",
       "      <td>6791</td>\n",
       "      <td>101</td>\n",
       "      <td>0.0178</td>\n",
       "      <td>72.400002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-24</td>\n",
       "      <td>6794</td>\n",
       "      <td>101</td>\n",
       "      <td>0.0204</td>\n",
       "      <td>69.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  timestamp_  station  freeway  occupancy      speed\n",
       "0 2019-01-24     6784      101     0.0000  69.000000\n",
       "1 2019-01-24     6785      101     0.0077  71.400002\n",
       "2 2019-01-24     6786      101     0.0242  71.800003\n",
       "3 2019-01-24     6791      101     0.0178  72.400002\n",
       "4 2019-01-24     6794      101     0.0204  69.000000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Omnisci.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Model\n",
    "\n",
    "## Including Weather"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in weather data from Omnisci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T19:33:25.131582Z",
     "start_time": "2019-05-13T19:33:25.023948Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe shape:  (4333, 8)\n"
     ]
    }
   ],
   "source": [
    "# read in traffic metadata from omnisci:\n",
    "\n",
    "query_traffic_meta = \"select * from caltrans_traffic_d04_metatable_weatherID\"\n",
    "\n",
    "df_traffic_metadata = OmnisciHandle.con.select_ipc(query_traffic_meta)\n",
    "print(\"Dataframe shape: \",df_traffic_metadata.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T19:33:25.262024Z",
     "start_time": "2019-05-13T19:33:25.133562Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe shape:  (71159, 7)\n"
     ]
    }
   ],
   "source": [
    "# read in weather data from omnisci:\n",
    "\n",
    "cols = \"timestamp_, \\\n",
    "hourlydrybulbtemperature, \\\n",
    "hourlyprecipitation, \\\n",
    "hourlyrelativehumidity, \\\n",
    "hourlyvisibility, \\\n",
    "hourlywindspeed, \\\n",
    "weather_station_id\"\n",
    "\n",
    "query_weather = \"select \"+ cols + \" from ncdc_weather_clean_190511\"\n",
    "# query_weather = \"select * from ncdc_weather_clean_190511\"\n",
    "\n",
    "df_weather = OmnisciHandle.con.select_ipc(query_weather)\n",
    "print(\"Dataframe shape: \",df_weather.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T19:33:25.343736Z",
     "start_time": "2019-05-13T19:33:25.263905Z"
    }
   },
   "outputs": [],
   "source": [
    "df_101Weather = df_Omnisci.set_index('timestamp_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T19:33:26.124740Z",
     "start_time": "2019-05-13T19:33:25.345455Z"
    }
   },
   "outputs": [],
   "source": [
    "traffic_tojoin = df_traffic_metadata[['id','weather_station_id']].set_index('id')\n",
    "df_101WeatherID_joined = df_101Weather.join(traffic_tojoin, on='station')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Join weather and Traffic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T19:33:26.132333Z",
     "start_time": "2019-05-13T19:33:26.126575Z"
    }
   },
   "outputs": [],
   "source": [
    "# pick important weather things:\n",
    "\n",
    "important_weather_columns = ['timestamp_','weather_station_id','hourlyprecipitation','hourlyvisibility','hourlywindspeed']\n",
    "\n",
    "important_weather_data = df_weather[important_weather_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T19:33:26.545164Z",
     "start_time": "2019-05-13T19:33:26.133832Z"
    }
   },
   "outputs": [],
   "source": [
    "# sort values to prepare for merge_asof function. does not work otherwise\n",
    "df_101WeatherID_joined=df_101WeatherID_joined.sort_values(by=['timestamp_'])\n",
    "important_weather_data = important_weather_data.sort_values(by=['timestamp_'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T19:33:27.702600Z",
     "start_time": "2019-05-13T19:33:26.546930Z"
    }
   },
   "outputs": [],
   "source": [
    "join_key = ['timestamp_']\n",
    "df_101_all = pd.merge_asof(left=df_101WeatherID_joined,\n",
    "                      right=important_weather_data,\n",
    "                      on=join_key,\n",
    "                      by='weather_station_id',\n",
    "                          direction='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T19:33:31.320823Z",
     "start_time": "2019-05-13T19:33:27.704505Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>occupancy</th>\n",
       "      <th>speed</th>\n",
       "      <th>hourlyprecipitation</th>\n",
       "      <th>hourlyvisibility</th>\n",
       "      <th>hourlywindspeed</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>station</th>\n",
       "      <th>timestamp_</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">6784</th>\n",
       "      <th>2019-01-01 00:00:00</th>\n",
       "      <td>0.0026</td>\n",
       "      <td>67.900002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 01:00:00</th>\n",
       "      <td>0.0009</td>\n",
       "      <td>67.699997</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 02:00:00</th>\n",
       "      <td>0.0003</td>\n",
       "      <td>67.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 03:00:00</th>\n",
       "      <td>0.0002</td>\n",
       "      <td>69.400002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 04:00:00</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>70.099998</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             occupancy      speed  hourlyprecipitation  \\\n",
       "station timestamp_                                                       \n",
       "6784    2019-01-01 00:00:00     0.0026  67.900002                  0.0   \n",
       "        2019-01-01 01:00:00     0.0009  67.699997                  0.0   \n",
       "        2019-01-01 02:00:00     0.0003  67.500000                  0.0   \n",
       "        2019-01-01 03:00:00     0.0002  69.400002                  0.0   \n",
       "        2019-01-01 04:00:00     0.0001  70.099998                  0.0   \n",
       "\n",
       "                             hourlyvisibility  hourlywindspeed  \n",
       "station timestamp_                                              \n",
       "6784    2019-01-01 00:00:00              10.0               10  \n",
       "        2019-01-01 01:00:00              10.0                8  \n",
       "        2019-01-01 02:00:00              10.0                9  \n",
       "        2019-01-01 03:00:00              10.0                6  \n",
       "        2019-01-01 04:00:00              10.0                9  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_cols = ['station','timestamp_','occupancy','speed','hourlyprecipitation','hourlyvisibility','hourlywindspeed']\n",
    "df_traffic_weather = (df_101_all[data_cols].set_index(['station','timestamp_'])\n",
    "                      .sort_values(['station','timestamp_']))\n",
    "\n",
    "df_traffic_weather.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T19:33:50.000228Z",
     "start_time": "2019-05-13T19:33:31.352394Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var1(t-12)</th>\n",
       "      <th>var2(t-12)</th>\n",
       "      <th>var3(t-12)</th>\n",
       "      <th>var4(t-12)</th>\n",
       "      <th>var5(t-12)</th>\n",
       "      <th>var1(t-11)</th>\n",
       "      <th>var2(t-11)</th>\n",
       "      <th>var3(t-11)</th>\n",
       "      <th>var4(t-11)</th>\n",
       "      <th>var5(t-11)</th>\n",
       "      <th>...</th>\n",
       "      <th>var1(t+4)</th>\n",
       "      <th>var2(t+4)</th>\n",
       "      <th>var3(t+4)</th>\n",
       "      <th>var4(t+4)</th>\n",
       "      <th>var5(t+4)</th>\n",
       "      <th>var1(t+5)</th>\n",
       "      <th>var2(t+5)</th>\n",
       "      <th>var3(t+5)</th>\n",
       "      <th>var4(t+5)</th>\n",
       "      <th>var5(t+5)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.006232</td>\n",
       "      <td>0.836039</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.002157</td>\n",
       "      <td>0.832792</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>...</td>\n",
       "      <td>0.097315</td>\n",
       "      <td>0.784091</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.089406</td>\n",
       "      <td>0.839286</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.002157</td>\n",
       "      <td>0.832792</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.000719</td>\n",
       "      <td>0.829545</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.089406</td>\n",
       "      <td>0.839286</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.076702</td>\n",
       "      <td>0.837662</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000719</td>\n",
       "      <td>0.829545</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000479</td>\n",
       "      <td>0.860390</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.076702</td>\n",
       "      <td>0.837662</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.059923</td>\n",
       "      <td>0.840909</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000479</td>\n",
       "      <td>0.860390</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000240</td>\n",
       "      <td>0.871753</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.059923</td>\n",
       "      <td>0.840909</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.049616</td>\n",
       "      <td>0.847403</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000240</td>\n",
       "      <td>0.871753</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000719</td>\n",
       "      <td>0.865260</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.049616</td>\n",
       "      <td>0.847403</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028523</td>\n",
       "      <td>0.844156</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 90 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   var1(t-12)  var2(t-12)  var3(t-12)  var4(t-12)  var5(t-12)  var1(t-11)  \\\n",
       "0    0.006232    0.836039         0.0        0.04    0.277778    0.002157   \n",
       "1    0.002157    0.832792         0.0        0.04    0.222222    0.000719   \n",
       "2    0.000719    0.829545         0.0        0.04    0.250000    0.000479   \n",
       "3    0.000479    0.860390         0.0        0.04    0.166667    0.000240   \n",
       "4    0.000240    0.871753         0.0        0.04    0.250000    0.000719   \n",
       "\n",
       "   var2(t-11)  var3(t-11)  var4(t-11)  var5(t-11)    ...      var1(t+4)  \\\n",
       "0    0.832792         0.0        0.04    0.222222    ...       0.097315   \n",
       "1    0.829545         0.0        0.04    0.250000    ...       0.089406   \n",
       "2    0.860390         0.0        0.04    0.166667    ...       0.076702   \n",
       "3    0.871753         0.0        0.04    0.250000    ...       0.059923   \n",
       "4    0.865260         0.0        0.04    0.250000    ...       0.049616   \n",
       "\n",
       "   var2(t+4)  var3(t+4)  var4(t+4)  var5(t+4)  var1(t+5)  var2(t+5)  \\\n",
       "0   0.784091        0.0       0.04   0.166667   0.089406   0.839286   \n",
       "1   0.839286        0.0       0.04   0.083333   0.076702   0.837662   \n",
       "2   0.837662        0.0       0.04   0.000000   0.059923   0.840909   \n",
       "3   0.840909        0.0       0.04   0.000000   0.049616   0.847403   \n",
       "4   0.847403        0.0       0.04   0.000000   0.028523   0.844156   \n",
       "\n",
       "   var3(t+5)  var4(t+5)  var5(t+5)  \n",
       "0        0.0       0.04   0.083333  \n",
       "1        0.0       0.04   0.000000  \n",
       "2        0.0       0.04   0.000000  \n",
       "3        0.0       0.04   0.000000  \n",
       "4        0.0       0.04   0.000000  \n",
       "\n",
       "[5 rows x 90 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_lag = 12\n",
    "n_steps = 6\n",
    "reframed, key, scaled, scaler1 = train_utils.format_model_data(df_train, n_lag, n_steps)\n",
    "\n",
    "reframed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T19:33:50.007130Z",
     "start_time": "2019-05-13T19:33:50.001915Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'occupancy': 'var1',\n",
       " 'speed': 'var2',\n",
       " 'hourlyprecipitation': 'var3',\n",
       " 'hourlyvisibility': 'var4',\n",
       " 'hourlywindspeed': 'var5'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T19:33:50.085700Z",
     "start_time": "2019-05-13T19:33:50.008981Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['var1(t+1)', 'var2(t+1)', 'var3(t+1)', 'var4(t+1)', 'var5(t+1)', 'var1(t+2)', 'var2(t+2)', 'var3(t+2)', 'var4(t+2)', 'var5(t+2)', 'var1(t+3)', 'var2(t+3)', 'var3(t+3)', 'var4(t+3)', 'var5(t+3)', 'var1(t+4)', 'var2(t+4)', 'var3(t+4)', 'var4(t+4)', 'var5(t+4)', 'var1(t+5)', 'var3(t+5)', 'var4(t+5)', 'var5(t+5)', 'var1(t)', 'var2(t)', 'var3(t)', 'var4(t)', 'var5(t)']\n"
     ]
    }
   ],
   "source": [
    "# TO-DO: FIX HOW THIS WORKS, VERY MANUAL AS OF NOW\n",
    "#drop_cols = []\n",
    "cols = list(reframed.columns)\n",
    "\n",
    "drop_1 = [c for c in cols if '(t+' in c]\n",
    "drop_2 = [c for c in cols if '(t)' in c]\n",
    "\n",
    "drop_1.remove('var2(t+5)')\n",
    "\n",
    "drop_cols = drop_1 + drop_2\n",
    "\n",
    "print(drop_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T19:34:11.385879Z",
     "start_time": "2019-05-13T19:34:09.074417Z"
    }
   },
   "outputs": [],
   "source": [
    "reframed.drop(drop_cols, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T19:34:21.747194Z",
     "start_time": "2019-05-13T19:34:21.741791Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training set: 5485197\n",
      "Size of Validation set: 609466\n",
      "Size of Testing set: 1\n",
      "(6094664, 61)\n"
     ]
    }
   ],
   "source": [
    "# define split\n",
    "train_ratio = 0.9\n",
    "val_ratio = 0.1\n",
    "\n",
    "train_val = int(reframed.shape[0] * train_ratio)\n",
    "\n",
    "val_test = train_val + int(reframed.shape[0] * val_ratio)\n",
    "\n",
    "print(\"Size of training set:\", train_val)\n",
    "print(\"Size of Validation set:\", val_test-train_val)\n",
    "print(\"Size of Testing set:\", reframed.shape[0]-val_test)\n",
    "#define number of steps in to the future\n",
    "\n",
    "print(reframed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T19:34:32.804869Z",
     "start_time": "2019-05-13T19:34:32.795371Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5485197, 1, 60) (5485197,) (1, 1, 60) (1,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Data\n",
    "values = reframed.values\n",
    "train = values[:train_val, :]\n",
    "val = values[train_val:val_test, :]\n",
    "test = values[val_test:, :]\n",
    "\n",
    "\n",
    "# split into input and outputs\n",
    "train_X, train_y = train[:, :-1], train[:, -1]\n",
    "val_X, val_y = val[:, :-1], val[:, -1]\n",
    "test_X, test_y = test[:, :-1], test[:, -1]\n",
    "\n",
    "# reshape input to be 3D [samples, timesteps, features]\n",
    "train_X = train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))\n",
    "val_X = val_X.reshape((val_X.shape[0], 1, val_X.shape[1]))\n",
    "test_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))\n",
    "\n",
    "print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T19:34:41.590774Z",
     "start_time": "2019-05-13T19:34:37.294405Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0513 19:34:37.307110 140533743929088 tf_logging.py:161] <tensorflow.python.keras.layers.recurrent.LSTM object at 0x7fd070343b00>: Note that this layer is not optimized for performance. Please use tf.keras.layers.CuDNNLSTM for better performance on GPU.\n",
      "W0513 19:34:41.256218 140533743929088 tf_logging.py:161] <tensorflow.python.keras.layers.recurrent.LSTM object at 0x7fd0703be4a8>: Note that this layer is not optimized for performance. Please use tf.keras.layers.CuDNNLSTM for better performance on GPU.\n"
     ]
    }
   ],
   "source": [
    "# The LSTM model\n",
    "my_model = Sequential()\n",
    "\n",
    "my_model.add(LSTM(input_shape=(train_X.shape[1], train_X.shape[2]), units=75, return_sequences=True))\n",
    "my_model.add(Dropout(0.3))\n",
    "\n",
    "my_model.add(LSTM(units=150, return_sequences=False))\n",
    "my_model.add(Dropout(0.2))\n",
    "\n",
    "my_model.add(Dense(units=1))\n",
    "my_model.add(Activation('linear'))\n",
    "\n",
    "opt = optimizers.Adam(lr=0.01, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "my_model.compile(loss='mse', optimizer='adam')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T19:46:14.477221Z",
     "start_time": "2019-05-13T19:35:01.298660Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5485197 samples, validate on 609466 samples\n",
      "Epoch 1/30\n",
      "5485197/5485197 - 27s - loss: 0.0498 - val_loss: 0.0062\n",
      "Epoch 2/30\n",
      "5485197/5485197 - 23s - loss: 0.0119 - val_loss: 0.0054\n",
      "Epoch 3/30\n",
      "5485197/5485197 - 23s - loss: 0.0099 - val_loss: 0.0052\n",
      "Epoch 4/30\n",
      "5485197/5485197 - 22s - loss: 0.0091 - val_loss: 0.0052\n",
      "Epoch 5/30\n",
      "5485197/5485197 - 22s - loss: 0.0086 - val_loss: 0.0052\n",
      "Epoch 6/30\n",
      "5485197/5485197 - 21s - loss: 0.0084 - val_loss: 0.0052\n",
      "Epoch 7/30\n",
      "5485197/5485197 - 22s - loss: 0.0082 - val_loss: 0.0052\n",
      "Epoch 8/30\n",
      "5485197/5485197 - 22s - loss: 0.0080 - val_loss: 0.0051\n",
      "Epoch 9/30\n",
      "5485197/5485197 - 22s - loss: 0.0079 - val_loss: 0.0051\n",
      "Epoch 10/30\n",
      "5485197/5485197 - 21s - loss: 0.0078 - val_loss: 0.0051\n",
      "Epoch 11/30\n",
      "5485197/5485197 - 21s - loss: 0.0076 - val_loss: 0.0050\n",
      "Epoch 12/30\n",
      "5485197/5485197 - 21s - loss: 0.0075 - val_loss: 0.0050\n",
      "Epoch 13/30\n",
      "5485197/5485197 - 21s - loss: 0.0074 - val_loss: 0.0050\n",
      "Epoch 14/30\n",
      "5485197/5485197 - 22s - loss: 0.0074 - val_loss: 0.0050\n",
      "Epoch 15/30\n",
      "5485197/5485197 - 21s - loss: 0.0073 - val_loss: 0.0050\n",
      "Epoch 16/30\n",
      "5485197/5485197 - 21s - loss: 0.0072 - val_loss: 0.0050\n",
      "Epoch 17/30\n",
      "5485197/5485197 - 21s - loss: 0.0071 - val_loss: 0.0050\n",
      "Epoch 18/30\n",
      "5485197/5485197 - 22s - loss: 0.0071 - val_loss: 0.0050\n",
      "Epoch 19/30\n",
      "5485197/5485197 - 24s - loss: 0.0070 - val_loss: 0.0050\n",
      "Epoch 20/30\n",
      "5485197/5485197 - 25s - loss: 0.0070 - val_loss: 0.0050\n",
      "Epoch 21/30\n",
      "5485197/5485197 - 21s - loss: 0.0069 - val_loss: 0.0050\n",
      "Epoch 22/30\n",
      "5485197/5485197 - 21s - loss: 0.0069 - val_loss: 0.0050\n",
      "Epoch 23/30\n",
      "5485197/5485197 - 22s - loss: 0.0068 - val_loss: 0.0050\n",
      "Epoch 24/30\n",
      "5485197/5485197 - 23s - loss: 0.0068 - val_loss: 0.0050\n",
      "Epoch 25/30\n",
      "5485197/5485197 - 22s - loss: 0.0067 - val_loss: 0.0050\n",
      "Epoch 26/30\n",
      "5485197/5485197 - 23s - loss: 0.0067 - val_loss: 0.0050\n",
      "Epoch 27/30\n",
      "5485197/5485197 - 23s - loss: 0.0066 - val_loss: 0.0050\n",
      "Epoch 28/30\n",
      "5485197/5485197 - 22s - loss: 0.0066 - val_loss: 0.0050\n",
      "Epoch 29/30\n",
      "5485197/5485197 - 23s - loss: 0.0065 - val_loss: 0.0050\n",
      "Epoch 30/30\n",
      "5485197/5485197 - 22s - loss: 0.0065 - val_loss: 0.0049\n"
     ]
    }
   ],
   "source": [
    "history = my_model.fit(train_X, train_y, epochs=30, batch_size=30000, validation_data=(val_X, val_y), verbose=2, shuffle=True)\n",
    "\n",
    "#history = my_model.fit(train_X, train_y, epochs=50, batch_size=50000, validation_split=0.2, verbose=2, shuffle=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T21:21:05.538915Z",
     "start_time": "2019-05-13T21:21:05.483843Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-16b435b16438>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# plot history\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "# plot history\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-11T22:59:42.281034Z",
     "start_time": "2019-05-11T22:56:40.856508Z"
    }
   },
   "outputs": [],
   "source": [
    "# make a prediction\n",
    "yhat = my_model.predict(test_X)\n",
    "test_X = test_X.reshape((test_X.shape[0], test_X.shape[2]))\n",
    "\n",
    "\n",
    "# invert scaling for forecast\n",
    "inv_yhat = np.concatenate((yhat, test_X[:, 1:]), axis=1)\n",
    "inv_yhat = scaler1.inverse_transform(inv_yhat)\n",
    "inv_yhat = inv_yhat[:,0]\n",
    "\n",
    "# invert scaling for actual\n",
    "test_y = test_y.reshape((len(test_y), 1))\n",
    "inv_y = np.concatenate((test_y, test_X[:, 1:]), axis=1)\n",
    "inv_y = scaler1.inverse_transform(inv_y)\n",
    "inv_y = inv_y[:,0]\n",
    "\n",
    "import math\n",
    "# calculate RMSE\n",
    "rmse = math.sqrt(mean_squared_error(inv_y, inv_yhat))\n",
    "print('Test RMSE: %.3f' % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T19:46:15.476309Z",
     "start_time": "2019-05-13T19:46:15.433059Z"
    }
   },
   "outputs": [],
   "source": [
    "# save model to use later\n",
    "save_t_model = True\n",
    "\n",
    "if save_t_model:\n",
    "    my_model.save('../models/190513_2130_TrafficAndWeather_final.h5')\n",
    "    \n",
    "del my_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-11T23:00:03.655068Z",
     "start_time": "2019-05-11T22:59:58.474167Z"
    }
   },
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import figure\n",
    "figure(num=None, figsize=(20, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "\n",
    "plt.plot(inv_y)\n",
    "plt.plot(inv_yhat)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-11T23:00:12.253951Z",
     "start_time": "2019-05-11T23:00:11.936548Z"
    }
   },
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import figure\n",
    "\n",
    "figure(num=None, figsize=(20, 6), dpi=80, facecolor='y', edgecolor='k')\n",
    "\n",
    "week_num = 0\n",
    "\n",
    "num_weeks = 1\n",
    "\n",
    "plt.plot(inv_y[week_num*7*24:week_num*7*24 + num_weeks*(7*24)])\n",
    "plt.plot(inv_yhat[week_num*7*24:week_num*7*24 + num_weeks*(7*24)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-11T23:00:20.721543Z",
     "start_time": "2019-05-11T23:00:20.414932Z"
    }
   },
   "outputs": [],
   "source": [
    "figure(num=None, figsize=(20, 6), dpi=80, facecolor='y', edgecolor='k')\n",
    "\n",
    "s = slice(400,500)\n",
    "\n",
    "plt.plot(inv_y[s])\n",
    "plt.plot(inv_yhat[s])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backup stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-11T12:33:56.421020Z",
     "start_time": "2019-05-11T12:32:54.560402Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# back up model\n",
    "# design network\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mae', optimizer='adam')\n",
    "# fit network\n",
    "history = model.fit(train_X, train_y, epochs=10, batch_size=50000, validation_data=(val_X, val_y), verbose=2, shuffle=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:traffic_demo]",
   "language": "python",
   "name": "conda-env-traffic_demo-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
